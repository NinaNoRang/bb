{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"191007_softmax.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"qgM5buct4SJO","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","x_data = [[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]] #vectors\n","y_data = [[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0],[1,0,0],[1,0,0]] #one hot encoding\n","X = tf.placeholder(tf.float32, shape=[None, 4])\n","Y = tf.placeholder(tf.float32, shape=[None, 3])\n","W = tf.Variable(tf.random_normal([4,3]))\n","b = tf.Variable(tf.random_normal([3]))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVaB7cNX4X_E","colab_type":"code","colab":{}},"source":["model_LC = tf.add(tf.matmul(X,W),b) # Linear Combination\n","model = tf.nn.softmax(model_LC) # Softmax\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model_LC, labels=Y))\n","train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n","\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    \n","    #Training\n","    for step in range(2001):\n","        c, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n","        print(step, c)\n","    \n","    #Testing\n","    test1 = sess.run(model, feed_dict={X: [[1,11,7,9]]})\n","    print(test1,sess.run(tf.argmax(test1,1)))"],"execution_count":0,"outputs":[]}]}